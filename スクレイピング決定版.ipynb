{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ozawa-nami/test/blob/main/%E3%82%B9%E3%82%AF%E3%83%AC%E3%82%A4%E3%83%94%E3%83%B3%E3%82%B0%E6%B1%BA%E5%AE%9A%E7%89%88.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPFnqPiB_NI1"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "import gspread\n",
        "\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdWFrdPI_ZpB"
      },
      "outputs": [],
      "source": [
        "!pip install selenium\n",
        "!pip install webdriver_manager pyvirtualdisplay\n",
        "!apt-get update\n",
        "!apt-get install -y xvfb wget\n",
        "!wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "!apt-get install -y ./google-chrome-stable_current_amd64.deb\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "\n",
        "# 仮想ディスプレイの起動\n",
        "display = Display(visible=0, size=(1024, 768))\n",
        "display.start()\n",
        "\n",
        "# Chrome のオプションとサービスの設定\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "options.add_argument('--headless')\n",
        "\n",
        "s = Service(ChromeDriverManager().install())\n",
        "#s = Service(ChromeDriverManager(\"116.0.5845.140\").install())\n",
        "\n",
        "\n",
        "# Chrome ブラウザの起動\n",
        "driver = webdriver.Chrome(service=s, options=options)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r83vNMj5WWuL"
      },
      "outputs": [],
      "source": [
        "\n",
        "#正常に動きます。N/A#とか入ってても大丈夫\n",
        "\n",
        "# 必要なライブラリのインポート\n",
        "import gspread  # Google Sheetsとの連携に使用します\n",
        "import google.auth  # 認証情報の取得に使用します\n",
        "import time  # ウェイト処理に使用します\n",
        "from google.colab import auth  # Google Colab環境での認証に使用します\n",
        "from google_auth_oauthlib.flow import InstalledAppFlow  # ローカル環境での認証に使用します\n",
        "from selenium import webdriver  # ウェブスクレイピングに使用します\n",
        "from selenium.webdriver.chrome.service import Service  # Chromeドライバの設定に使用します\n",
        "from webdriver_manager.chrome import ChromeDriverManager  # Chromeドライバの自動インストールに使用します\n",
        "from bs4 import BeautifulSoup  # HTMLの解析に使用します\n",
        "from selenium.webdriver.support.ui import WebDriverWait  # 要素の待機に使用します\n",
        "from selenium.webdriver.support import expected_conditions as EC  # 条件の指定に使用します\n",
        "from oauth2client.client import GoogleCredentials  # Google APIの認証に使用します\n",
        "from soupsieve import SelectorSyntaxError\n",
        "\n",
        "\n",
        "# Googleドライブへの認証を行います\n",
        "auth.authenticate_user()\n",
        "\n",
        "# 認証情報を保存するための変数を初期化します\n",
        "creds = None\n",
        "\n",
        "# Google Colab環境での認証\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    creds, _ = google.auth.default()\n",
        "else:\n",
        "    # ローカル環境の場合、クライアントの秘密ファイルを使用して認証を行います\n",
        "    # 以下の行の`scraping-384605-1e7cd0ea5328.json`は、Google Cloud Consoleから取得したクライアントの秘密ファイル名に置き換えてください\n",
        "    flow = InstalledAppFlow.from_client_secrets_file('scraping-384605-1e7cd0ea5328.json', scopes)\n",
        "    creds = flow.run_local_server(port=0)\n",
        "\n",
        "# gspreadライブラリに認証情報を設定し、Googleスプレッドシートにアクセスできるようにします\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# スクレイピング対象のスプレッドシートのURLとシート名を定義します\n",
        "spreadsheet_url = \"https://docs.google.com/spreadsheets/d/1tGojEuhrflajdU67ewvfyQQCcHybdu08c23CWL4TB94/edit#gid=1454186977\"\n",
        "worksheet_name = \"副業エージェント\"\n",
        "\n",
        "# スプレッドシートを開き、シートを指定します\n",
        "sh = gc.open_by_url(spreadsheet_url)\n",
        "worksheet = sh.worksheet(worksheet_name)\n",
        "\n",
        "# スプレッドシートからURLとセレクタの情報を読み込みます\n",
        "url_list = worksheet.range(\"A6:A13\")\n",
        "selector_list = worksheet.range(\"B6:B13\")\n",
        "\n",
        "# スクレイピング結果を格納するためのリストを初期化します\n",
        "results = []\n",
        "\n",
        "# ChromeのWebドライバを設定し、ブラウザを起動します\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "options.add_argument('--headless')\n",
        "\n",
        "s = Service(ChromeDriverManager().install())   #　webdriverとChromeのバージョン合わない時は、直接指定\n",
        "#ChromeDriverManager(\"116.0.5845.140\").install()\n",
        "driver = webdriver.Chrome(service=s, options=options)\n",
        "\n",
        "\n",
        "\n",
        "# 各URLに対してスクレイピングを行います\n",
        "for i, url_cell in enumerate(url_list):\n",
        "    url = url_cell.value\n",
        "    if not url:\n",
        "        continue  # URLがない場合はスキップする\n",
        "\n",
        "    # ウェブドライバに指定したURLを開かせます\n",
        "    try:\n",
        "        driver.get(url)\n",
        "    except Exception as e:\n",
        "        print(f\"URL '{url}' の読み込み中にエラーが発生しました: {str(e)}\")\n",
        "        continue\n",
        "\n",
        "    # ページ上の全ての要素が読み込まれるまで待機します（最大で5秒）\n",
        "    WebDriverWait(driver, 1).until(EC.presence_of_all_elements_located)\n",
        "\n",
        "    # ページのHTMLを取得します\n",
        "    html = driver.page_source.encode('utf-8')\n",
        "\n",
        "    # BeautifulSoupでHTMLをパースします\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "    # セレクタを取得します\n",
        "    selector = selector_list[i].value\n",
        "    if not selector:\n",
        "        # セレクタが存在しない場合、結果のリストに空文字列を追加します\n",
        "        results.append((\"\", url_cell))\n",
        "        continue\n",
        "\n",
        "\n",
        "\n",
        "    # セレクタに対応するテキストを取得します\n",
        "    try:\n",
        "        text = soup.select_one(selector)\n",
        "    except SelectorSyntaxError:\n",
        "        print(f\"セレクタ '{selector}' が不適切です。スキップします。\")\n",
        "        continue\n",
        "\n",
        "    if text:\n",
        "        try:\n",
        "            # テキストを浮動小数点数に変換します\n",
        "            float_val = float(text.text.replace(\",\", \"\"))\n",
        "            results.append((float_val, url_cell))\n",
        "        except ValueError:\n",
        "            # テキストが数値に変換できない場合、そのまま結果のリストに追加します\n",
        "            results.append((text.text, url_cell))\n",
        "    else:\n",
        "        # テキストが存在しない場合、結果のリストに空文字列を追加します\n",
        "        results.append((\"\", url_cell))\n",
        "\n",
        "\n",
        "# スクレイピング結果を一括で書き込みます\n",
        "cells_to_update = []\n",
        "for result, cell in results:\n",
        "    cells_to_update.append(gspread.models.Cell(cell.row, 4, result))  # 列に結果を書き込みます（列の列番号を表します）\n",
        "worksheet.update_cells(cells_to_update)\n",
        "\n",
        "\n",
        "# ウェブドライバを閉じます\n",
        "driver.quit()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZyZT45n87By",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d92e31e-43b7-4fe7-bc0f-fccd3612049b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URL 'https://www.kango-roo.com/career/search/results.php?work_types%5B%5D=3' の読み込み中に指定した要素が見つからないため、TimeoutExceptionが発生しました。\n"
          ]
        }
      ],
      "source": [
        "#時間かかる場合\n",
        "\n",
        "# 必要なライブラリのインポート\n",
        "import gspread  # Google Sheetsとの連携に使用します\n",
        "import google.auth  # 認証情報の取得に使用します\n",
        "import time  # ウェイト処理に使用します\n",
        "from google.colab import auth  # Google Colab環境での認証に使用します\n",
        "from google_auth_oauthlib.flow import InstalledAppFlow  # ローカル環境での認証に使用します\n",
        "from selenium import webdriver  # ウェブスクレイピングに使用します\n",
        "from selenium.webdriver.chrome.service import Service  # Chromeドライバの設定に使用します\n",
        "from webdriver_manager.chrome import ChromeDriverManager  # Chromeドライバの自動インストールに使用します\n",
        "from bs4 import BeautifulSoup  # HTMLの解析に使用します\n",
        "from selenium.webdriver.support.ui import WebDriverWait  # 要素の待機に使用します\n",
        "from selenium.webdriver.support import expected_conditions as EC  # 条件の指定に使用します\n",
        "from oauth2client.client import GoogleCredentials  # Google APIの認証に使用します\n",
        "\n",
        "from selenium.common.exceptions import TimeoutException\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "\n",
        "# Googleドライブへの認証を行います\n",
        "auth.authenticate_user()\n",
        "\n",
        "# 認証情報を保存するための変数を初期化します\n",
        "creds = None\n",
        "\n",
        "# Google Colab環境での認証\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    creds, _ = google.auth.default()\n",
        "else:\n",
        "    # ローカル環境の場合、クライアントの秘密ファイルを使用して認証を行います\n",
        "    # 以下の行の`scraping-384605-1e7cd0ea5328.json`は、Google Cloud Consoleから取得したクライアントの秘密ファイル名に置き換えてください\n",
        "    flow = InstalledAppFlow.from_client_secrets_file('scraping-384605-1e7cd0ea5328.json', scopes)\n",
        "    creds = flow.run_local_server(port=0)\n",
        "\n",
        "# gspreadライブラリに認証情報を設定し、Googleスプレッドシートにアクセスできるようにします\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# スクレイピング対象のスプレッドシートのURLとシート名を定義します\n",
        "spreadsheet_url = \"https://docs.google.com/spreadsheets/d/1NwFp7_HG64TFHFE7VfppyqDgnMUZ6UI8DYJzR7ETOvc/edit#gid=1064975884\"\n",
        "worksheet_name = \"看護師\"\n",
        "\n",
        "# スプレッドシートを開き、シートを指定します\n",
        "sh = gc.open_by_url(spreadsheet_url)\n",
        "worksheet = sh.worksheet(worksheet_name)\n",
        "\n",
        "# スプレッドシートからURLとセレクタの情報を読み込みます\n",
        "url_list = worksheet.range(\"A5:A81\")\n",
        "selector_list = worksheet.range(\"B5:B81\")\n",
        "\n",
        "# スクレイピング結果を格納するためのリストを初期化します\n",
        "results = []\n",
        "\n",
        "# ChromeのWebドライバを設定し、ブラウザを起動します\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "options.add_argument('--headless')\n",
        "\n",
        "s = Service(ChromeDriverManager().install())\n",
        "driver = webdriver.Chrome(service=s, options=options)\n",
        "\n",
        "# 各URLに対してスクレイピングを行います\n",
        "for i, url_cell in enumerate(url_list):\n",
        "    url = url_cell.value\n",
        "    if not url:\n",
        "        continue  # URLがない場合はスキップする\n",
        "\n",
        "    # ウェブドライバに指定したURLを開かせます\n",
        "    try:\n",
        "        driver.get(url)\n",
        "    except Exception as e:\n",
        "        print(f\"URL '{url}' の読み込み中にエラーが発生しました: {str(e)}\")\n",
        "        continue\n",
        "\n",
        "    # セレクタを取得します\n",
        "    selector = selector_list[i].value\n",
        "    if not selector:\n",
        "        # セレクタが存在しない場合、結果のリストに空文字列を追加します\n",
        "        results.append((\"\", url_cell))\n",
        "        continue\n",
        "\n",
        "    # ページ上の要素が読み込まれるまで待機します（最大で100秒）\n",
        "    try:\n",
        "        WebDriverWait(driver, 100).until(EC.presence_of_element_located((By.CSS_SELECTOR, selector)))\n",
        "    except TimeoutException:\n",
        "        print(f\"URL '{url}' の読み込み中に指定した要素が見つからないため、TimeoutExceptionが発生しました。\")\n",
        "        continue\n",
        "\n",
        "    # ページのHTMLを取得します\n",
        "    html = driver.page_source.encode('utf-8')\n",
        "\n",
        "    # BeautifulSoupでHTMLをパースします\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "    # セレクタに対応するテキストを取得します\n",
        "    text = soup.select_one(selector)\n",
        "    if text:\n",
        "        try:\n",
        "            # テキストを浮動小数点数に変換します\n",
        "            float_val = float(text.text.replace(\",\", \"\"))\n",
        "            results.append((float_val, url_cell))\n",
        "        except ValueError:\n",
        "            # テキストが数値に変換できない場合、そのまま結果のリストに追加します\n",
        "            results.append((text.text, url_cell))\n",
        "    else:\n",
        "        # テキストが存在しない場合、結果のリストに空文字列を追加します\n",
        "        results.append((\"\", url_cell))\n",
        "\n",
        "\n",
        "# # 各URLに対してスクレイピングを行います\n",
        "# for i, url_cell in enumerate(url_list):\n",
        "#     url = url_cell.value\n",
        "#     if not url:\n",
        "#         continue  # URLがない場合はスキップする\n",
        "\n",
        "#     # ウェブドライバに指定したURLを開かせます\n",
        "#     try:\n",
        "#         driver.get(url)\n",
        "#     except Exception as e:\n",
        "#         print(f\"URL '{url}' の読み込み中にエラーが発生しました: {str(e)}\")\n",
        "#         continue\n",
        "\n",
        "#     # # ページ上の全ての要素が読み込まれるまで待機します（最大で30秒）\n",
        "#     # WebDriverWait(driver, 100).until(EC.presence_of_all_elements_located)\n",
        "#     WebDriverWait(driver, 100).until(EC.presence_of_element_located((By.CSS_SELECTOR, selector)))\n",
        "\n",
        "\n",
        "#     # ページのHTMLを取得します\n",
        "#     html = driver.page_source.encode('utf-8')\n",
        "\n",
        "#     # BeautifulSoupでHTMLをパースします\n",
        "#     soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "#     # セレクタを取得します\n",
        "#     selector = selector_list[i].value\n",
        "#     if not selector:\n",
        "#         # セレクタが存在しない場合、結果のリストに空文字列を追加します\n",
        "#         results.append((\"\", url_cell))\n",
        "#         continue\n",
        "\n",
        "#     # セレクタに対応するテキストを取得します\n",
        "#     text = soup.select_one(selector)\n",
        "#     if text:\n",
        "#         try:\n",
        "#             # テキストを浮動小数点数に変換します\n",
        "#             float_val = float(text.text.replace(\",\", \"\"))\n",
        "#             results.append((float_val, url_cell))\n",
        "#         except ValueError:\n",
        "#             # テキストが数値に変換できない場合、そのまま結果のリストに追加します\n",
        "#             results.append((text.text, url_cell))\n",
        "#     else:\n",
        "#         # テキストが存在しない場合、結果のリストに空文字列を追加します\n",
        "#         results.append((\"\", url_cell))\n",
        "\n",
        "\n",
        "# スクレイピング結果を一括で書き込みます\n",
        "cells_to_update = []\n",
        "for result, cell in results:\n",
        "    cells_to_update.append(gspread.models.Cell(cell.row, 3, result))  # 結果を書き込みます（3はC列の列番号を表します）\n",
        "worksheet.update_cells(cells_to_update)\n",
        "\n",
        "\n",
        "# ウェブドライバを閉じます\n",
        "driver.quit()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "48qDS5L-M2Zf",
        "outputId": "0c875789-0518-45e8-ee1d-e97e6335ad7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://doda.jp/DodaFront/View/JobSearchList.action?sid=TopSearch&usrclk=PC_logout_kyujinSearchArea_searchButton\n",
            "https://www.jaic-g.com/\n",
            "https://www.r-agent.com/kensaku/kinmuchi/?rndmprm=04541440461742190157587242902320230331155405764\n",
            "https://www.r-agent.com/kensaku/gyoukai/industry1-01/\n",
            "https://directscout.recruit.co.jp/offers/\n",
            "https://mynavi-job20s.jp/job/o/list\n",
            "https://doda-x.jp/job/search/\n",
            "https://career.levtech.jp/engineer/offer/search/?top_type=100&job_specify=none&keyword=\n",
            "https://www.kango-roo.com/career/search/results.php?emp_types%5B%5D=1\n",
            "https://kango-oshigoto.jp/search/%E5%B8%B8%E5%8B%A4(%E5%A4%9C%E5%8B%A4%E6%9C%89%E3%82%8A)-%E6%97%A5%E5%8B%A4%E5%B8%B8%E5%8B%A4/\n",
            "https://www.nursejinzaibank.com/\n",
            "https://next.rikunabi.com/search/\n",
            "https://mc-nurse.net/jobs/search/\n",
            "https://iishuusyoku.com/03/03-03-1.php\n",
            "https://www.ptotjinzaibank.com/pt/search_result/1?job_type=5&free_keyword=\n",
            "https://iryouworker.com/search/search/?workstyle_id%5B%5D=1&workstyle_id%5B%5D=2&workstyle_id%5B%5D=3&hospital_name=\n",
            "https://careerstart.co.jp/\n",
            "https://job-medley.com/ans/search/?utf8=%E2%9C%93&job_category_code=ans&hw=1&employment_type%5B%5D=1&employment_type%5B%5D=2\n",
            "https://www.rikuraku.net/\n",
            "https://rikunabi-yakuzaishi.jp/\n",
            "https://octavia-es.com/\n",
            "https://www.jmsc.co.jp/entry/list/?issubmit=1&job%5Bincome_year_from%5D=&job%5Bincome_year_to%5D=\n",
            "https://tokyo-yakuzaishi-kyujin.com/jobs/?salary_type=&salary_min=&salary_max=\n",
            "https://pcareer.m3.com/positions/list/1?action_type=search&primary_sort_by=order_by_recommend\n",
            "https://hoikushi-worker.com/freeword/freeword_6/\n",
            "https://ten-ki.jp/job?income%5B%5D=&jobs%5B%5D=\n",
            "https://www.daini-agent.jp/\n",
            "https://woman-type.jp/job-search/?routeway=16&search=&hopejob=&prlist=\n",
            "https://www.ss-shop.jp/\n",
            "https://shu-katu-express.com/\n",
            "https://kaigoworker.jp/\n",
            "https://www.workport.co.jp/all/search/?sort=3\n",
            "https://www.robertwalters.co.jp/jobs.html?q=\n",
            "https://career.prismy.jp/recruitments?sort=weight_desc\n",
            "https://www.lineaconsulting.co.jp/joblists/\n",
            "https://www.liber.co.jp/\n",
            "https://www.randstad.co.jp/tenshoku/\n",
            "https://www.movin.co.jp/\n",
            "https://www.massmedian.co.jp/search/\n",
            "https://pharma.mynavi.jp/\n",
            "https://hoiku.mynavi.jp/r/\n",
            "https://tenshoku.mynavi.jp/search/\n",
            "https://kango.mynavi.jp/r/fd_0247-0248/\n",
            "https://mynavi-creator.jp/job/o/list\n",
            "https://mynavi-creator.jp/job/o/list\n",
            "https://mynavi-agent.jp/jobsearch/result.php\n",
            "https://mynavi-agent.jp/jobsearch/job1_01/result.php\n",
            "https://mynavi-agent.jp/jobsearch/arc_00/ar_99/result.php\n",
            "https://www.michaelpage.co.jp/jobs?0=7141\n",
            "https://www.procommit.co.jp/job/page/24\n",
            "https://www.pharmate.jp/search/list.html\n"
          ]
        },
        {
          "ename": "WebDriverException",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-d90b92f76f1c>\u001b[0m in \u001b[0;36m<cell line: 53>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# リクエストの送信\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# ページ上のすべての要素が読み込まれるまで待機（15秒でタイムアウト判定）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;34m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"url\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"alert\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mWebDriverException\u001b[0m: Message: unknown error: net::ERR_CONNECTION_TIMED_OUT\n  (Session info: headless chrome=114.0.5735.198)\nStacktrace:\n#0 0x557a4b82b4e3 <unknown>\n#1 0x557a4b55ac76 <unknown>\n#2 0x557a4b552c7f <unknown>\n#3 0x557a4b544ca2 <unknown>\n#4 0x557a4b546412 <unknown>\n#5 0x557a4b5450ca <unknown>\n#6 0x557a4b544168 <unknown>\n#7 0x557a4b543fa0 <unknown>\n#8 0x557a4b5429bf <unknown>\n#9 0x557a4b542fed <unknown>\n#10 0x557a4b55cb06 <unknown>\n#11 0x557a4b5ce9e5 <unknown>\n#12 0x557a4b5b6012 <unknown>\n#13 0x557a4b5ce30e <unknown>\n#14 0x557a4b5b5de3 <unknown>\n#15 0x557a4b58b2dd <unknown>\n#16 0x557a4b58c34e <unknown>\n#17 0x557a4b7eb3e4 <unknown>\n#18 0x557a4b7ef3d7 <unknown>\n#19 0x557a4b7f9b20 <unknown>\n#20 0x557a4b7f0023 <unknown>\n#21 0x557a4b7be1aa <unknown>\n#22 0x557a4b8146b8 <unknown>\n#23 0x557a4b814847 <unknown>\n#24 0x557a4b824243 <unknown>\n#25 0x7f55969ea609 start_thread\n"
          ]
        }
      ],
      "source": [
        "#1行ずつ書き出す\n",
        "\n",
        "import gspread\n",
        "import google.auth\n",
        "from google.colab import auth\n",
        "from google_auth_oauthlib.flow import InstalledAppFlow\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import time\n",
        "\n",
        "#Googleドライブの認証\n",
        "auth.authenticate_user()\n",
        "\n",
        "creds = None\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    creds, _ = google.auth.default()\n",
        "else:\n",
        "    flow = InstalledAppFlow.from_client_secrets_file('scraping-384605-1e7cd0ea5328.json', scopes)\n",
        "    creds = flow.run_local_server(port=0)\n",
        "\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "#スプレッドシートのURLとシート名\n",
        "spreadsheet_url = \"https://docs.google.com/spreadsheets/d/1D9En1wvE4BfIM3ptWD-AdcB4n4JeSPEGn287xDViSNs/edit#gid=295107686\"\n",
        "worksheet_name = \"スクレイピング\"\n",
        "\n",
        "#スプレッドシートの読み込み\n",
        "sh = gc.open_by_url(spreadsheet_url)\n",
        "worksheet = sh.worksheet(worksheet_name)\n",
        "\n",
        "#URLとセレクタの取得　A5以下にURL指定、B5セル以下にセレクタ指定\n",
        "url_list = worksheet.range(\"A5:A288\")\n",
        "selector_list = worksheet.range(\"B5:B288\")\n",
        "\n",
        "#空のリストの作成\n",
        "results = []\n",
        "\n",
        "#ブラウザの起動\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "options.add_argument('--headless')\n",
        "\n",
        "s = Service(ChromeDriverManager().install())\n",
        "driver = webdriver.Chrome(service=s, options=options)\n",
        "\n",
        "# 各URLに対してスクレイピング\n",
        "for i, url_cell in enumerate(url_list):\n",
        "    # URLの取得\n",
        "    url = url_cell.value\n",
        "    if not url:\n",
        "        break\n",
        "\n",
        "    # URLの確認\n",
        "    print(url)\n",
        "\n",
        "    # リクエストの送信\n",
        "    driver.get(url)\n",
        "\n",
        "    # ページ上のすべての要素が読み込まれるまで待機（15秒でタイムアウト判定）\n",
        "    WebDriverWait(driver, 15).until(EC.presence_of_all_elements_located)\n",
        "\n",
        "    html = driver.page_source.encode('utf-8')\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "    # # セレクタの取得\n",
        "    # selector = selector_list[i].value\n",
        "    # if not selector:\n",
        "    #     worksheet.update_cell(i+5, 3, \"\")  # C列に空文字列を書き込む\n",
        "    #     continue\n",
        "\n",
        "  # セレクタの取得\n",
        "    selector = selector_list[i].value\n",
        "    if not selector or selector == '#N/A':\n",
        "        worksheet.update_cell(i+5, 3, \"\")  # C列に空文字列を書き込む\n",
        "        continue\n",
        "\n",
        "\n",
        "\n",
        "    # テキストの取得\n",
        "    text = soup.select_one(selector)\n",
        "    if text:\n",
        "        try:\n",
        "            float_val = float(text.text.replace(\",\", \"\"))  # 数値として扱える場合は、float型に変換\n",
        "            worksheet.update_cell(i+5, 23, float_val)  # C列に数値を書き込む\n",
        "        except ValueError:\n",
        "            worksheet.update_cell(i+5, 23, text.text)  # 数値でない場合は、文字列として書き込む\n",
        "        time.sleep(1)  # Google Sheets APIの書き込みリミットを超えないように1秒待つ\n",
        "    else:\n",
        "        worksheet.update_cell(i+5, 23, \"\")  # C列に空文字列を書き込む\n",
        "        time.sleep(1)  # Google Sheets APIの書き込みリミットを超えないように1秒待つ\n",
        "\n",
        "\n",
        "    # 指定された待ち時間だけ処理を停止\n",
        "    sleeptime = 2  # 待ち時間を指定（単位は秒）\n",
        "    time.sleep(sleeptime)\n",
        "\n",
        "# ブラウザを終了\n",
        "driver.quit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhuTaw43ExGd"
      },
      "outputs": [],
      "source": [
        "#見出しの取得\n",
        "\n",
        "!pip install gspread beautifulsoup4 requests\n",
        "\n",
        "import gspread\n",
        "import google.auth\n",
        "from google.colab import auth\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import time\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Googleドライブの認証\n",
        "auth.authenticate_user()\n",
        "\n",
        "creds, _ = google.auth.default()\n",
        "\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# スプレッドシートのURLとシート名\n",
        "spreadsheet_url = \"https://docs.google.com/spreadsheets/d/1boKdEkPqZS_LMISwwYb0UtamwR1JrxD7FQjH7kQ3hoQ/edit#gid=0\"\n",
        "worksheet_name = \"シート1\"\n",
        "\n",
        "# スプレッドシートの読み込み\n",
        "sh = gc.open_by_url(spreadsheet_url)\n",
        "worksheet = sh.worksheet(worksheet_name)\n",
        "\n",
        "# URLの取得　A5以下にURL指定\n",
        "url_cells = worksheet.col_values(1)[4:]  # Pythonのリストは0から始まるため、5行目はインデックス4に相当します。\n",
        "\n",
        "# 各URLに対してスクレイピング\n",
        "for i, url in enumerate(url_cells, start=5):  # 開始番号を5に設定\n",
        "    if not url:\n",
        "        worksheet.update_cell(i, 3, \"\")  # C列に空文字を書き込む\n",
        "        continue\n",
        "\n",
        "    # リクエストの送信\n",
        "    try:\n",
        "        res = requests.get(url)\n",
        "        res.raise_for_status()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Request error for {url}: {e}\")\n",
        "        worksheet.update_cell(i, 3, \"\")  # C列に空文字を書き込む\n",
        "        continue\n",
        "\n",
        "    # ページの解析\n",
        "    soup = BeautifulSoup(res.text, 'html.parser')\n",
        "    # H2とH3の見出しの取得\n",
        "    headers = soup.find_all(['h2', 'h3'])\n",
        "\n",
        "    # H2, H3見出しを整頓し、リストに追加\n",
        "    headers_list = []\n",
        "    for h in headers:\n",
        "      if h.name == 'h2':\n",
        "          headers_list.append(f\"H2: {h.text}\")\n",
        "      elif h.name == 'h3':\n",
        "        headers_list.append(f\"H3: {h.text}\")\n",
        "\n",
        "    # ソース上の順番を崩さず、書き込み規則に従った文字列を作成\n",
        "    headers_text = \"\\n\".join(headers_list)\n",
        "\n",
        "\n",
        "    # 結果をスプレッドシートに書き込む\n",
        "    worksheet.update_cell(i, 3, headers_text)\n",
        "\n",
        "    # APIの利用制限を考慮して待ち時間を設ける\n",
        "    time.sleep(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brQH5qO0PmYP"
      },
      "outputs": [],
      "source": [
        "# 必要なライブラリのインストール\n",
        "#!pip install gspread beautifulsoup4 requests\n",
        "\n",
        "import gspread\n",
        "import google.auth\n",
        "from google.colab import auth\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import time\n",
        "import re\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Googleドライブの認証\n",
        "auth.authenticate_user()\n",
        "creds, _ = google.auth.default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# スプレッドシートのURLとシート名\n",
        "spreadsheet_url = \"https://docs.google.com/spreadsheets/d/1boKdEkPqZS_LMISwwYb0UtamwR1JrxD7FQjH7kQ3hoQ/edit#gid=0\"\n",
        "worksheet_name = \"シート1\"\n",
        "\n",
        "# スプレッドシートの読み込み\n",
        "sh = gc.open_by_url(spreadsheet_url)\n",
        "worksheet = sh.worksheet(worksheet_name)\n",
        "\n",
        "# URLの取得 A5セル以下にURL指定\n",
        "url_cells = worksheet.col_values(1)[4:]\n",
        "\n",
        "# 各URLに対してスクレイピングと情報取得\n",
        "for i, url in enumerate(url_cells, start=5):\n",
        "    if not url:\n",
        "        worksheet.update_cell(i, 2, \"\")  # B列に空文字を書き込む\n",
        "        worksheet.update_cell(i, 3, \"\")  # C列に空文字を書き込む\n",
        "        worksheet.update_cell(i, 4, \"\")  # D列に空文字を書き込む\n",
        "        worksheet.update_cell(i, 5, \"\")  # E列に空文字を書き込む\n",
        "        worksheet.update_cell(i, 6, \"\")  # F列に空文字を書き込む\n",
        "        worksheet.update_cell(i, 7, \"\")  # G列に空文字を書き込む\n",
        "        continue\n",
        "\n",
        "    # リクエストの送信\n",
        "    try:\n",
        "        res = requests.get(url)\n",
        "        res.raise_for_status()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Request error for {url}: {e}\")\n",
        "        worksheet.update_cell(i, 2, \"\")  # B列に空文字を書き込む\n",
        "        worksheet.update_cell(i, 3, \"\")  # C列に空文字を書き込む\n",
        "        worksheet.update_cell(i, 4, \"\")  # D列に空文字を書き込む\n",
        "        worksheet.update_cell(i, 5, \"\")  # E列に空文字を書き込む\n",
        "        worksheet.update_cell(i, 6, \"\")  # F列に空文字を書き込む\n",
        "        worksheet.update_cell(i, 7, \"\")  # G列に空文字を書き込む\n",
        "        continue\n",
        "\n",
        "    # ページの解析\n",
        "    soup = BeautifulSoup(res.text, 'html.parser')\n",
        "\n",
        "\n",
        "    # H1タイトル\n",
        "    h1_tag = soup.find('h1')\n",
        "    h1_title = h1_tag.text.strip() if h1_tag else \"N/A\"\n",
        "\n",
        "    # H2とH3の見出しの取得\n",
        "    headers = soup.find\n",
        "\n",
        "    # H2とH3の見出しの取得\n",
        "    headers = soup.find_all(['h2', 'h3'])\n",
        "\n",
        "    # H2, H3見出しを整頓し、リストに追加\n",
        "    headers_list = []\n",
        "    for h in headers:\n",
        "        if h.name == 'h2':\n",
        "            headers_list.append(f\"H2: {h.text.strip()}\")\n",
        "        elif h.name == 'h3':\n",
        "            headers_list.append(f\"H3: {h.text.strip()}\")\n",
        "\n",
        "    # ソース上の順番を崩さず、書き込み規則に従った文字列を作成\n",
        "    headers_text = \"\\n\".join(headers_list)\n",
        "\n",
        "    # サイトの文字数\n",
        "    site_text = soup.get_text()\n",
        "    site_text_length = len(re.sub(r'\\s+', ' ', site_text))\n",
        "\n",
        "    # ディスクリプション（metaタグから取得）\n",
        "    description = soup.find('meta', attrs={'name': 'description'})\n",
        "    description_content = description.get('content').strip() if description else \"N/A\"\n",
        "\n",
        "    # 総リンク数のカウント\n",
        "    all_links = soup.find_all('a')\n",
        "    total_link_count = len(all_links)\n",
        "\n",
        "    # 画像数のカウント\n",
        "    images = soup.find_all('img')\n",
        "    image_count = len(images)\n",
        "\n",
        "    # 出力\n",
        "    worksheet.update_cell(i, 2, h1_title)  # B列にタイトルを書き込む\n",
        "    worksheet.update_cell(i, 3, headers_text)  # C列にH2H3情報を書き込む\n",
        "    worksheet.update_cell(i, 4, site_text_length)  # D列にサイトの文字数を書き込む\n",
        "    worksheet.update_cell(i, 5, description_content)  # E列にサイトのディスクリぷしょんを書き込む\n",
        "    worksheet.update_cell(i, 6, total_link_count)  # F列に総リンク数を書き込む\n",
        "    worksheet.update_cell(i, 7, image_count)  # G列に画像数を書き込む\n",
        "\n",
        "    # APIの利用制限を考慮して待ち時間を設ける\n",
        "    time.sleep(2)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "16ChOv7EiQljfQ-RmhY6D4DPeuud3NzhJ",
      "authorship_tag": "ABX9TyMqEasAUGVE19wzFqERzHdR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}